{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataGeneration import *\n",
    "import polars as pl\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import psutil\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset,DataLoader,random_split\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_usage():\n",
    "    process = psutil.Process()\n",
    "    print(f\"Memory usage: {process.memory_info().rss / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = datagen()\n",
    "a.apply_simulation()\n",
    "df = a.retrieve_df()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.df_to_tensor()\n",
    "a.standard_normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_len, hidden_size_1, hidden_size_2, out_len):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.LSTM(input_len, hidden_size_1, batch_first=True),\n",
    "            nn.LSTM(hidden_size_1, hidden_size_2, batch_first=True),\n",
    "            nn.Linear(hidden_size_2, out_len)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        h1 = torch.zeros(1, x.size(0), self.model[0].hidden_size).to(x.device)\n",
    "        c1 = torch.zeros(1, x.size(0), self.model[0].hidden_size).to(x.device)\n",
    "        h2 = torch.zeros(1, x.size(0), self.model[1].hidden_size).to(x.device)\n",
    "        c2 = torch.zeros(1, x.size(0), self.model[1].hidden_size).to(x.device)\n",
    "        \n",
    "\n",
    "        x, (h1, c1) = self.model[0](x, (h1, c1))\n",
    "        \n",
    "\n",
    "        x, (h2, c2) = self.model[1](x, (h2, c2))\n",
    "        \n",
    "  \n",
    "        x = self.model[2](x)  \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RNN(nn.Module):\n",
    "#     def __init__(self, input_len, hidden_size_1, hidden_size_2, out_len):\n",
    "#         super(RNN, self).__init__()\n",
    "        \n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.GRU(input_len, hidden_size_1, batch_first=True),\n",
    "#             nn.GRU(hidden_size_1, hidden_size_2, batch_first=True),\n",
    "#             nn.Linear(hidden_size_2, out_len)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         h1 = torch.zeros(1, x.size(0), self.model[0].hidden_size).to(x.device)\n",
    "      \n",
    "#         h2 = torch.zeros(1, x.size(0), self.model[1].hidden_size).to(x.device)\n",
    "       \n",
    "        \n",
    "\n",
    "#         x, _ = self.model[0](x, h1)\n",
    "        \n",
    "\n",
    "#         x, _= self.model[1](x, h2)\n",
    "        \n",
    "  \n",
    "#         x = self.model[2](x)  \n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(mp.cpu_count())\n",
    "device = torch.device('mps')\n",
    "\n",
    "Model = RNN(4,64,32,2)\n",
    "Model = Model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(Model.parameters(),lr=0.001,eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, epochs=100, batch_size=256,val_split=0.1):\n",
    "    \n",
    "    val_split = val_split\n",
    "    val_size = int(val_split * len(dataset))\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    batch_size = 256\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=mp.cpu_count(),\n",
    "                              pin_memory=True,persistent_workers = True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,num_workers=mp.cpu_count(),\n",
    "                            pin_memory=True,persistent_workers = True)\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    train_list=[]\n",
    "    val_list= []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_X)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val = X_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                output = model(X_val)\n",
    "                loss = criterion(output, y_val)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        val_loss /= len(val_loader)\n",
    "        # if epoch+1 % 10 == 0:\n",
    "        toc = time.perf_counter()\n",
    "        print(f'Epoch: {epoch}, Elapsed: {(toc - tic):.0f} sec')\n",
    "        tic = time.perf_counter()\n",
    "        print(\"Loss for Training on Epoch \" + str(epoch) + \" is \" + str(val_loss))\n",
    "        val_list.append(val_loss)\n",
    "        train_list.append(train_loss)\n",
    "    return train_list,val_list\n",
    "            #print_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_np= a.X_train_norm.astype(np.float32)\n",
    "y_train_np= a.y_train_norm.astype(np.float32)\n",
    "X_train_tensor = torch.from_numpy(X_train_np)\n",
    "y_train_tensor = torch.from_numpy(y_train_np)\n",
    "# X_train_tensor = torch.FloatTensor(a.X_train.astype(np.float32))\n",
    "# y_train_tensor = torch.FloatTensor(a.y_train.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloss,valloss=train(Model, dataset, epochs=100, batch_size=256,val_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Model.eval()\n",
    "    y_pred = Model(torch.from_numpy(a.X_test_norm.astype(np.float32)).to(device))\n",
    "    test_loss = criterion(y_pred, torch.from_numpy(a.y_test_norm.astype(np.float32)).to(device))\n",
    "    print('test loss is {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(trainloss) + 1)\n",
    "plt.plot(epochs, trainloss, 'r', label='Training loss')\n",
    "plt.plot(epochs, valloss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "class tensorflow_LSTM:\n",
    "    def __init__(self,input_shape,hidden_unit1,hidden_unit2,num_output_variable):\n",
    "\n",
    "      self.Input_layer = Input(shape=(None,input_shape), dtype='float32') \n",
    "      x = LSTM(units = hidden_unit1, return_sequences= True)(self.Input_layer)\n",
    "      x = LSTM(units = hidden_unit2, return_sequences= True)(x)\n",
    "      x = Dense(units = num_output_variable,activation='linear')(x)\n",
    "\n",
    "      self.model = Model(inputs= self.Input_layer,outputs=x)\n",
    "      # plot_model(self.model, \"model.png\",show_shapes=True)\n",
    "      \n",
    "\n",
    "    def get_model(self):\n",
    "         return self.model\n",
    "\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tensorflow_LSTM(4,64,32,2)\n",
    "model=model.get_model()\n",
    "model.compile(\n",
    "      loss=MeanSquaredError(),\n",
    "      optimizer=Adam())\n",
    "\n",
    "history = model.fit(a.X_train_norm, a.y_train_norm, epochs=100, batch_size=256, validation_split=0.1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(a.X_test_norm,a.y_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "x_scaler = joblib.load('standardscaler/xscaler.pkl')\n",
    "y_scaler = joblib.load('standardscaler/yscaler.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = np.linspace(-100, 100, 100000, endpoint=True)\n",
    "\n",
    "x_upper = list()\n",
    "x_lower = list()\n",
    "y_plot = list()\n",
    "\n",
    "for i in y:\n",
    "    sqrt = np.sqrt(-2688000 * i**2 + 15772800000)\n",
    "    if sqrt >= 0:\n",
    "        y_plot.append(i)\n",
    "        x_upper.append((-4400 * i + sqrt) / 212000)\n",
    "        x_lower.append((-4400 * i - sqrt) / 212000)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "\n",
    "def manual_minmax_inverse(X_scaled, X_min, X_max):\n",
    "    return X_scaled * (X_max - X_min) + X_min\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "X_test = torch.from_numpy(a.X_test_norm.astype(np.float32))\n",
    "y_test = a.y_test\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "# plot the first 10 samples and their trajectories\n",
    "Model.eval()\n",
    "y_predict = Model(X_test).cpu()\n",
    "y_predict = y_scaler.inverse_transform(y_predict.detach().numpy().reshape(-1,2)).reshape(-1,10,2)\n",
    "#y_test =  y_scaler.inverse_transform(y_test.numpy().reshape(-1,2)).reshape(-1,10,2)\n",
    "X_plot =  a.X_test\n",
    "\n",
    "\n",
    "for i in range(500):\n",
    "    if i == 0:  # only add label to 1 data point\n",
    "        plt.plot(X_plot[i, 0, 0], X_plot[i, 0, 1], marker=\"*\", markersize=15,color='orange')\n",
    "        plt.plot(y_test[i, :, 0], y_test[i, :, 1], color='cyan', lw=2, label='Test')\n",
    "        plt.plot(y_predict[i, :, 0], y_predict[i, :, 1], color='black', lw=2, ls=':', label='Predicted')\n",
    "    else:\n",
    "        plt.plot(X_plot[i, 0, 0], X_plot[i, 0, 1], marker=\"*\", markersize=15,color='orange')\n",
    "        plt.plot(y_test[i, :, 0], y_test[i, :, 1], color='cyan', lw=2)\n",
    "        plt.plot(y_predict[i, :, 0], y_predict[i, :, 1], color='black', lw=2, ls=':')\n",
    "\n",
    "    \n",
    "# plot stability region        \n",
    "plt.plot(x_lower, y_plot, color='steelblue')\n",
    "plt.plot(x_upper, y_plot, color='steelblue')\n",
    "plt.ylim([-100, 100])\n",
    "plt.xlim([-2, 2])\n",
    "\n",
    "plt.xlabel(\"C_A - C_As\")\n",
    "plt.ylabel(\"T - T_s\")\n",
    "plt.legend()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "x_scaler = joblib.load('standardscaler/xscaler.pkl')\n",
    "y_scaler = joblib.load('standardscaler/yscaler.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = np.linspace(-100, 100, 100000, endpoint=True)\n",
    "\n",
    "x_upper = list()\n",
    "x_lower = list()\n",
    "y_plot = list()\n",
    "\n",
    "for i in y:\n",
    "    sqrt = np.sqrt(-2688000 * i**2 + 15772800000)\n",
    "    if sqrt >= 0:\n",
    "        y_plot.append(i)\n",
    "        x_upper.append((-4400 * i + sqrt) / 212000)\n",
    "        x_lower.append((-4400 * i - sqrt) / 212000)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "X_test = torch.from_numpy(a.X_test_norm.astype(np.float32))\n",
    "y_test = a.y_test\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "# plot the first 10 samples and their trajectories\n",
    "Model.eval()\n",
    "y_predict = Model(X_test).cpu()\n",
    "y_predict = y_scaler.inverse_transform(y_predict.detach().numpy().reshape(-1,2)).reshape(-1,10,2)\n",
    "#y_test =  y_scaler.inverse_transform(y_test.numpy().reshape(-1,2)).reshape(-1,10,2)\n",
    "X_plot =  a.X_test\n",
    "\n",
    "\n",
    "for i in range(500):\n",
    "    if i == 0:  # only add label to 1 data point\n",
    "        plt.plot(X_plot[i, 0, 0], X_plot[i, 0, 1], marker=\"*\", markersize=15,color='orange')\n",
    "        plt.plot(y_test[i, :, 0], y_test[i, :, 1], color='cyan', lw=2, label='Test')\n",
    "        plt.plot(y_predict[i, :, 0], y_predict[i, :, 1], color='black', lw=2, ls=':', label='Predicted')\n",
    "    else:\n",
    "        plt.plot(X_plot[i, 0, 0], X_plot[i, 0, 1], marker=\"*\", markersize=15,color='orange')\n",
    "        plt.plot(y_test[i, :, 0], y_test[i, :, 1], color='cyan', lw=2)\n",
    "        plt.plot(y_predict[i, :, 0], y_predict[i, :, 1], color='black', lw=2, ls=':')\n",
    "\n",
    "    \n",
    "# plot stability region        \n",
    "plt.plot(x_lower, y_plot, color='steelblue')\n",
    "plt.plot(x_upper, y_plot, color='steelblue')\n",
    "plt.ylim([-100, 100])\n",
    "plt.xlim([-2, 2])\n",
    "\n",
    "plt.xlabel(\"C_A - C_As\")\n",
    "plt.ylabel(\"T - T_s\")\n",
    "plt.legend()\n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
